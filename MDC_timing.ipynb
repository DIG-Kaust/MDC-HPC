{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-dimensional convolution timing benchmarks - single virtual source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: M.Ravasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook perfoms multi-dimensional convolution with the same reflection response(s) used in the Marchenko redatuming examples with the aim of comparing the performance of the core operation with respect to *data size* and *number of compute resources*. \n",
    "\n",
    "Here, we consider the case with a single virtual source. The notebook **MDCmulti_timing** is used to perform the same with multiple virtual sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import psutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import zarr\n",
    "import pylops\n",
    "import pylops_distributed\n",
    "import scooby\n",
    "\n",
    "from datetime import date\n",
    "from timeit import repeat\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from scipy.linalg import lstsq, solve\n",
    "from scipy.sparse.linalg import cg, lsqr\n",
    "from scipy.signal import convolve, filtfilt\n",
    "\n",
    "from pylops.basicoperators import *\n",
    "from pylops.waveeqprocessing.mdd       import MDC\n",
    "from pylops.utils.wavelets             import *\n",
    "from pylops.utils.seismicevents        import *\n",
    "from pylops.utils.tapers               import *\n",
    "from pylops.waveeqprocessing.marchenko import directwave\n",
    "from pylops.utils import dottest\n",
    "\n",
    "from pylops_distributed.utils import dottest as ddottest\n",
    "from pylops_distributed.basicoperators import Diagonal as dDiagonal\n",
    "from pylops_distributed.basicoperators import Identity as dIdentity\n",
    "from pylops_distributed.basicoperators import Roll as dRoll\n",
    "from pylops_distributed.waveeqprocessing.mdd import MDC as dMDC\n",
    "from pylops_distributed.waveeqprocessing.marchenko import Marchenko as dMarchenko\n",
    "from pylops_distributed.optimization.cg import cg as dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"STORE_PATH\"] = \"/project/fsenter/mrava/Marchenko3D/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish connection with Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_ram():\n",
    "    tmem = psutil.virtual_memory().total\n",
    "    return '{:.1f} GB'.format(tmem / (1024.0 ** 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pylops_distributed.utils.backend.dask(hardware='multi', client='be-linrgsn085:8786')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nworkers = len(np.array(list(client.ncores().values())))\n",
    "ncores = np.sum(np.array(list(client.ncores().values())))\n",
    "print('Nworkers', nworkers)\n",
    "print('Ncores', ncores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Input parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDC parameters\n",
    "nfmax = 300         # max frequency for MDC (#samples)\n",
    "darea = 1           # areal extent for spatial integration (not needed here...)\n",
    "subsampling = 8     # subsampling of src-recs compared to original data\n",
    "ffirst = True       # frequency in first axis of zarr file\n",
    "rechunk = True      # rechunk R\n",
    "rebalance = True    # rebalance R across nodes\n",
    "\n",
    "# Timing parameters\n",
    "nrepeat = min(2, subsampling+1)\n",
    "ntime = min(5, subsampling+1)\n",
    "\n",
    "# Input file names\n",
    "inputfile_aux = os.environ[\"STORE_PATH\"]+'3DMarchenko_auxiliary_2.npz' \n",
    "zarrfile = os.environ[\"STORE_PATH\"]+'input3D_sub%d%s.zarr' % \\\n",
    "    (subsampling, '_ffirst' if ffirst else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load auxiliary input (contains sources, recs, virtual source etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdata_aux = np.load(inputfile_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and visualize geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Receivers\n",
    "r = inputdata_aux['recs'][::subsampling].T\n",
    "nr = r.shape[1]\n",
    "dr = r[0,1]-r[0,0]\n",
    "\n",
    "# Sources\n",
    "s = inputdata_aux['srcs'][::subsampling].T\n",
    "ns = s.shape[1]\n",
    "ds = s[0,1]-s[0,0]\n",
    "\n",
    "# Virtual points\n",
    "vs = inputdata_aux['vs']\n",
    "\n",
    "# Time axis\n",
    "ot, dt, nt = 0, 2.5e-3, 601\n",
    "t = np.arange(nt)*dt\n",
    "\n",
    "# Density model\n",
    "rho = inputdata_aux['rho']\n",
    "z, x, y = inputdata_aux['z'], inputdata_aux['x'], inputdata_aux['y']\n",
    "\n",
    "plt.figure(figsize=(18,9))\n",
    "plt.imshow(rho[np.argmin(np.abs(x-vs[1]))].T, cmap='gray', extent = (x[0], x[-1], z[-1], z[0]))\n",
    "plt.scatter(r[0, ::10],  r[2, ::10], marker='v', s=150, c='b', edgecolors='k')\n",
    "plt.scatter(s[0, 5::10], s[2, 5::10], marker='*', s=150, c='r', edgecolors='k')\n",
    "plt.scatter(vs[0], vs[2], marker='.', s=250, c='m', edgecolors='k')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('x [m]'),plt.ylabel('y [m]'),plt.title('Model and Geometry')\n",
    "plt.xlim(x[0], x[-1]);\n",
    "\n",
    "plt.figure(figsize=(18,9))\n",
    "plt.imshow(rho[np.argmin(np.abs(y-vs[0]))].T, cmap='gray', extent = (y[0], y[-1], z[-1], z[0]))\n",
    "plt.scatter(r[1, ::10],  r[2, ::10], marker='v', s=150, c='b', edgecolors='k')\n",
    "plt.scatter(s[1, 5::10], s[2, 5::10], marker='*', s=150, c='r', edgecolors='k')\n",
    "plt.scatter(vs[1], vs[2], marker='.', s=250, c='m', edgecolors='k')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('y [m]'),plt.ylabel('z [m]'),plt.title('Model and Geometry')\n",
    "plt.xlim(y[0], y[-1]);\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.scatter(r[0],  r[1], marker='v', s=150, c='b', edgecolors='k')\n",
    "plt.scatter(s[0], s[1], marker='*', s=150, c='r', edgecolors='k')\n",
    "plt.scatter(vs[0], vs[1], marker='.', s=500, c='m', edgecolors='k')\n",
    "plt.axis('equal')\n",
    "plt.xlabel('x [m]'),plt.ylabel('y [m]'),plt.title('Top view Geometry')\n",
    "plt.xlim(x[0], x[-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read subsurface fields and wavelet to apply to subsurface fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0sub = inputdata_aux['G0'][:, ::subsampling]\n",
    "wav = ricker(t[:51], 20)[0]\n",
    "wav_c = np.argmax(wav)\n",
    "\n",
    "# Convolve with wavelet\n",
    "G0sub = np.apply_along_axis(convolve, 0, G0sub, wav, mode='full') \n",
    "G0sub = G0sub[wav_c:][:nt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Reflection response from Zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dRtwosided_fft = 2 * da.from_zarr(zarrfile)  # 2 * as per theory you need 2*R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nchunks = [max(nfmax // ncores, 1), ns, nr]\n",
    "if not ffirst:\n",
    "    dRtwosided_fft = dRtwosided_fft.transpose(2, 1, 0)\n",
    "if rechunk:\n",
    "    dRtwosided_fft = dRtwosided_fft.rechunk(nchunks)\n",
    "else:\n",
    "    nchunks = dRtwosided_fft.chunksize\n",
    "dRtwosided_fft = client.persist(dRtwosided_fft)\n",
    "client.rebalance(dRtwosided_fft)\n",
    "\n",
    "dRtwosided_fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create distributed MDC operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operator\n",
    "dRop = dMDC(dRtwosided_fft, nt=2*nt-1, nv=1, dt=dt, dr=darea, \n",
    "            twosided=True, saveGt=False)\n",
    "\n",
    "# Input focusing function\n",
    "dfd_plus = np.concatenate((np.fliplr(G0sub.T).T, np.zeros((nt-1, nr))))\n",
    "dfd_plus = da.from_array(dfd_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run standard redatuming as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp0_minus = dRop * dfd_plus.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0_minus = dp0_minus.compute()\n",
    "p0_minus = p0_minus.reshape((2*nt-1), nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, sharey=True, figsize=(16, 8))\n",
    "ax.imshow(p0_minus, cmap='gray', vmin=-1e3, vmax=1e3, \n",
    "          interpolation='sinc', extent=(0, nr, t[-1], -t[-1]))\n",
    "ax.set_title(r'$p_0^-$')\n",
    "ax.set_xlabel(r'$x_R$')\n",
    "ax.set_ylabel(r'$t$')\n",
    "ax.axis('tight')\n",
    "ax.set_ylim(0.5, -0.5)\n",
    "ax.set_xlim(700, 1100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp0_forw = dRop.matvec(dfd_plus.flatten())\n",
    "\n",
    "exctime = np.array(repeat(lambda: dp0_forw.compute(), number=ntime, repeat=nrepeat))\n",
    "meantime, stdtime = np.mean(exctime/ntime), np.std(exctime/ntime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(nworkers=nworkers, ncores=ncores, ram=total_ram(), \n",
    "                       subsampling=subsampling, ffirst=ffirst,\n",
    "                       meantime=meantime, stdtime=stdtime, \n",
    "                       nchunks=str(nchunks), rebalance=rebalance,\n",
    "                       nrepeat=nrepeat, ntime=ntime,\n",
    "                       time=date.today()), index=[0])\n",
    "\n",
    "# add to csv file\n",
    "header=True\n",
    "if os.path.isfile('Benchmarks/benchmark_forw.csv'):\n",
    "    df_other = pd.read_csv('Benchmarks/benchmark_forw.csv')\n",
    "    df = pd.concat([df_other, df])\n",
    "df.to_csv('Benchmarks/benchmark_forw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Benchmarks/benchmark_forw.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp0_adj = dRop.rmatvec(dfd_plus.flatten())\n",
    "\n",
    "exctime = np.array(repeat(lambda: dp0_adj.compute(), number=ntime, repeat=nrepeat))\n",
    "meantime, stdtime = np.mean(exctime/ntime), np.std(exctime/ntime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(nworkers=nworkers, ncores=ncores, ram=total_ram(), \n",
    "                       subsampling=subsampling, ffirst=ffirst,\n",
    "                       meantime=meantime, stdtime=stdtime, \n",
    "                       nchunks=str(nchunks), rebalance=rebalance,\n",
    "                       nrepeat=nrepeat, ntime=ntime,\n",
    "                       time=date.today()), index=[0])\n",
    "\n",
    "# add to csv file\n",
    "header=True\n",
    "if os.path.isfile('Benchmarks/benchmark_adj.csv'):\n",
    "    df_other = pd.read_csv('Benchmarks/benchmark_adj.csv')\n",
    "    df = pd.concat([df_other, df])\n",
    "df.to_csv('Benchmarks/benchmark_adj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Benchmarks/benchmark_adj.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scooby.Report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
